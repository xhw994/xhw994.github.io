<!DOCTYPE html>


  <html class="light page-post">


<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>搭建基于.NET生态的聚焦网络爬虫 | Xegnal</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content=".NET,">
  

  <meta name="description" content="萌芽&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;我曾经有段时间是很讨厌网络爬虫这种东西的。它们漫无目的地在互联网上东奔西走，窥探着一切想要被看到的和不想被看到的东西。回想起来，我初中二三年级的时候还会在网络上放一些初中生的无病呻吟和风花雪月的诗词。当时还和班里的才子和真·才女组成了一个诗词同好会之类的东西，每日浸淫于诗赋之间，互相切磋互相吹捧，颇有古时候举人的风采。但哪">
<meta name="keywords" content=".NET">
<meta property="og:type" content="article">
<meta property="og:title" content="搭建基于.NET生态的聚焦网络爬虫">
<meta property="og:url" content="https://xhw994.github.io/2019/07/29/20190729/index.html">
<meta property="og:site_name" content="Xegnal">
<meta property="og:description" content="萌芽&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;我曾经有段时间是很讨厌网络爬虫这种东西的。它们漫无目的地在互联网上东奔西走，窥探着一切想要被看到的和不想被看到的东西。回想起来，我初中二三年级的时候还会在网络上放一些初中生的无病呻吟和风花雪月的诗词。当时还和班里的才子和真·才女组成了一个诗词同好会之类的东西，每日浸淫于诗赋之间，互相切磋互相吹捧，颇有古时候举人的风采。但哪">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://xhw994.github.io/2019/07/29/20190729/1.png">
<meta property="og:updated_time" content="2021-01-17T06:44:11.049Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="搭建基于.NET生态的聚焦网络爬虫">
<meta name="twitter:description" content="萌芽&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;我曾经有段时间是很讨厌网络爬虫这种东西的。它们漫无目的地在互联网上东奔西走，窥探着一切想要被看到的和不想被看到的东西。回想起来，我初中二三年级的时候还会在网络上放一些初中生的无病呻吟和风花雪月的诗词。当时还和班里的才子和真·才女组成了一个诗词同好会之类的东西，每日浸淫于诗赋之间，互相切磋互相吹捧，颇有古时候举人的风采。但哪">
<meta name="twitter:image" content="https://xhw994.github.io/2019/07/29/20190729/1.png">

  

  
    <link rel="icon" href="/images/favicon/favicon.ico">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  
    <link rel="stylesheet" href="/css/personal-style.css">
  

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-138256872-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  

  


  
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

</head>
</html>
<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">导航</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">导航</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/archives/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/tag/"
            rel="noopener noreferrer"
            target="_self"
            >
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/link/"
            rel="noopener noreferrer"
            target="_self"
            >
            友链
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/about/"
            rel="noopener noreferrer"
            target="_self"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/search/"
            rel="noopener noreferrer"
            target="_self"
            >
            搜索
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#萌芽"><span class="toc-text">萌芽</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#爬虫"><span class="toc-text">爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#配置"><span class="toc-text">配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#使用配置文件"><span class="toc-text">使用配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用配置对象"><span class="toc-text">使用配置对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置文件与配置对象混用"><span class="toc-text">配置文件与配置对象混用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#上手"><span class="toc-text">上手</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自定义爬虫"><span class="toc-text">自定义爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#决策器"><span class="toc-text">决策器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#其他的组件"><span class="toc-text">其他的组件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#注册监听器"><span class="toc-text">注册监听器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#处理页面前"><span class="toc-text">处理页面前</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#处理页面后"><span class="toc-text">处理页面后</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#禁止爬取页面"><span class="toc-text">禁止爬取页面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#禁止爬取页面内超链接"><span class="toc-text">禁止爬取页面内超链接</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#提取DOM内所有的文字信息"><span class="toc-text">提取DOM内所有的文字信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#运行"><span class="toc-text">运行</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#小结"><span class="toc-text">小结</span></a></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-20190729" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">搭建基于.NET生态的聚焦网络爬虫</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2019.07.29</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>Xeon</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/随笔/">随笔</a>
  </span>



      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <h1 id="萌芽"><a href="#萌芽" class="headerlink" title="萌芽"></a>萌芽</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我曾经有段时间是很讨厌网络爬虫这种东西的。它们漫无目的地在互联网上东奔西走，窥探着一切想要被看到的和不想被看到的东西。回想起来，我初中二三年级的时候还会在网络上放一些初中生的无病呻吟和风花雪月的诗词。当时还和班里的才子和真·才女组成了一个诗词同好会之类的东西，每日浸淫于诗赋之间，互相切磋互相吹捧，颇有古时候举人的风采。但哪怕是中二的我也懂得，这些东西大多是见不得人的自娱自乐的产物（和现在如出一辙）。不是说有哪些会伤着人的语句，只是怕自己那稚嫩的文青风格被当作刻意的少年老成——也许我潜意识里确实有这样卖弄的心态——所以很怕被人看到吧。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那时流行一种被我们称作“萌芽体”的作文，是一种肆意引经据典，滥用排比，要么如黛玉般无端伤怀、要么装成个飞马的武将故作豪迈的文风，其命名来源于一本叫做《萌芽》的青年杂志，每期千篇一律的都是这种风格的文章，乍一看根本瞧不出这篇和那篇之间的区别，全是虚假空洞的屁话。但不幸的是，这些屁话在教师之间很是流行。它们通过堆砌华丽的辞藻，就像是要蹦出纸面一样地朝读者嘶吼着它们是多么优雅的艺术品。时间不充裕的阅卷老师看到这溢出纸面的“文气”，不消细看文章内容，只凭文章首尾的结构就可以打分，实在是方便还挑不出错。诚然，萌芽体对于作者的文学底蕴还是有很高的要求的，能从唐诗三百首里随手抄出几篇适用的句子的人，其文学功底一定能吊打大部分学生了。且比起初中生贫弱的生活经验，教师们更认同既定成型的诗词和习语这件事虽然令人不爽却也不是不能理解。但这并不能改变萌芽文等同于屁话这一真理。连散文都要借景抒情，言之有物。你一个萌芽体算老几？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我的作文虽说也会用些形容比喻，但终究没有跳出以叙事为主抒怀为辅的传统文章的路数。众所周知，叙事题材的质与量是和作者的阅历成正比的。应试教育的皮鞭逼着我每两三天就要写一篇作文出来，一个月一个月过去，我能写的内容越来越少，写出的内容也大同，成了只为了考试拿分的存在。后来我甚至开始在内容上胡编滥造，要按现在的话说就是失去了写作的灵魂。我明明把写作当成自我的诉求和与大人的对话方式，结果不论内容真假，反应在纸面上的评价并不会有什么区别。我也有想过不如放下自己的矜持，向萌芽体妥协。可惜做不到的事情就是做不到，在QQ空间上试水模仿的几篇文章都成了四不像，越看越恶心，被毕业后的我光速扫入了青春的垃圾堆。终于我醒悟了，明明用自己的方式写作就已经能拿学年第一了，为什么非要降维去学写不出实质内容的人用的旁门左道？既然自己这一路走来并无犯错，何必抛弃自己的风格呢？</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;顺带一提，如今的《萌芽》上萌芽体也不再泛滥，其内容回归《格言》之流的青少年文学，实在是令人欣慰。而不幸的是，我这几年的内心变化影响到了我的文字，写出来的东西像是变了质的萌芽体，成了旁门左道中的旁门左道。如果没有心境上的变化怕是很难回到当初大开大阖的文风了。那句话怎么说的来着：人终于会变成他们最讨厌的存在。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;唉怎么又讲了一堆屁话，我明明只是想表达我有一些不想被爬虫看到的内容的。总之，和一切科技一样，爬虫这一概念是不带有善恶的标签的。通用的爬虫，如Google搜索引擎的前端，是不会在乎你我的喜悲的。它们只会遵循着繁复的规则，日复一日地构建互联网的索引。而如果你像我一样多愁善感，你可以编写一个在乎你的感受的爬虫，意即聚焦型网络爬虫。而这这就是本文的目的了。</p>
<h1 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我选择使用.NET生态中人气最旺的Abot来完成这项任务。Abot爬虫由许多个小型的组件组成，拥有极高的可插拔性和可延伸性。它还使用了大量惰性初始化，最大化去掉了多余的运算，因此它的运行速度很快。可惜的是，由于维护人手的不足，Abot目前是不支持.NET Standard的。但如果不嫌麻烦的话稍微修改源代码再编译应该也不会很麻烦。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先创建一个空的.NET Framework控制台程序，然后在NuGet包管理器中安装Abot（<a href="https://github.com/sjdirect/abot" target="_blank" rel="noopener">源代码</a>）。注意不是AbotX，那是Abot的商业版本。</p>
<center><img src="/2019/07/29/20190729/1.png"></center>

<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abot提供了三种不同的配置方法：配置文件、配置对象、或是两者混用。</p>
<h3 id="使用配置文件"><a href="#使用配置文件" class="headerlink" title="使用配置文件"></a>使用配置文件</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此方式适用于.NET及ASP.NET环境下的程序。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在<code>app.config</code>或是<code>web.config</code>文件中加入如下字段，并进行相应的调整。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">configSections</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">section</span> <span class="attr">name</span>=<span class="string">"abot"</span> <span class="attr">type</span>=<span class="string">"Abot.Core.AbotConfigurationSectionHandler, Abot"</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">configSections</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">abot</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">crawlBehavior</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">maxConcurrentThreads</span>=<span class="string">"10"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">maxPagesToCrawl</span>=<span class="string">"1000"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">maxPagesToCrawlPerDomain</span>=<span class="string">"0"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">maxPageSizeInBytes</span>=<span class="string">"0"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">userAgentString</span>=<span class="string">"Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">crawlTimeoutSeconds</span>=<span class="string">"0"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">downloadableContentTypes</span>=<span class="string">"text/html, text/plain"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">isUriRecrawlingEnabled</span>=<span class="string">"false"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">isExternalPageCrawlingEnabled</span>=<span class="string">"false"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">isExternalPageLinksCrawlingEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">httpServicePointConnectionLimit</span>=<span class="string">"200"</span>  </span></span><br><span class="line"><span class="tag">      <span class="attr">httpRequestTimeoutInSeconds</span>=<span class="string">"15"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">httpRequestMaxAutoRedirects</span>=<span class="string">"7"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">isHttpRequestAutoRedirectsEnabled</span>=<span class="string">"true"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">isHttpRequestAutomaticDecompressionEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">isSendingCookiesEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">isSslCertificateValidationEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">isRespectUrlNamedAnchorOrHashbangEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">minAvailableMemoryRequiredInMb</span>=<span class="string">"0"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">maxMemoryUsageInMb</span>=<span class="string">"0"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">maxMemoryUsageCacheTimeInSeconds</span>=<span class="string">"0"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">maxCrawlDepth</span>=<span class="string">"1000"</span></span></span><br><span class="line"><span class="tag">	  <span class="attr">maxLinksPerPage</span>=<span class="string">"1000"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">isForcedLinkParsingEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">maxRetryCount</span>=<span class="string">"0"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">minRetryDelayInMilliseconds</span>=<span class="string">"0"</span></span></span><br><span class="line"><span class="tag">      /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">authorization</span></span></span><br><span class="line"><span class="tag">      <span class="attr">isAlwaysLogin</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">loginUser</span>=<span class="string">""</span></span></span><br><span class="line"><span class="tag">      <span class="attr">loginPassword</span>=<span class="string">""</span> /&gt;</span>	  </span><br><span class="line">    <span class="tag">&lt;<span class="name">politeness</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">isRespectRobotsDotTextEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">isRespectMetaRobotsNoFollowEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">	  <span class="attr">isRespectHttpXRobotsTagHeaderNoFollowEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">isRespectAnchorRelNoFollowEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">isIgnoreRobotsDotTextIfRootDisallowedEnabled</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">robotsDotTextUserAgentString</span>=<span class="string">"abot"</span></span></span><br><span class="line"><span class="tag">      <span class="attr">maxRobotsDotTextCrawlDelayInSeconds</span>=<span class="string">"5"</span> </span></span><br><span class="line"><span class="tag">      <span class="attr">minCrawlDelayPerDomainMilliSeconds</span>=<span class="string">"0"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">extensionValues</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">add</span> <span class="attr">key</span>=<span class="string">"key1"</span> <span class="attr">value</span>=<span class="string">"value1"</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">add</span> <span class="attr">key</span>=<span class="string">"key2"</span> <span class="attr">value</span>=<span class="string">"value2"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">extensionValues</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">abot</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span>    </span><br></pre></td></tr></table></figure>

<h3 id="使用配置对象"><a href="#使用配置对象" class="headerlink" title="使用配置对象"></a>使用配置对象</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建一个<code>Abot.Poco.CrawlConfiguration</code>对象并修改其中的内容：</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CrawlConfiguration crawlConfig = <span class="keyword">new</span> CrawlConfiguration</span><br><span class="line">&#123;</span><br><span class="line">  CrawlTimeoutSeconds = <span class="number">100</span>,</span><br><span class="line">  MaxConcurrentThreads = <span class="number">10</span>,</span><br><span class="line">  MaxPagesToCrawl = <span class="number">1000</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="配置文件与配置对象混用"><a href="#配置文件与配置对象混用" class="headerlink" title="配置文件与配置对象混用"></a>配置文件与配置对象混用</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CrawlConfiguration crawlConfig = AbotConfigurationSectionHandler.LoadFromXml().Convert();</span><br><span class="line">crawlConfig.MaxPagesToCrawl = <span class="number">0</span>; <span class="comment">// 无抓取上限</span></span><br></pre></td></tr></table></figure>

<h2 id="上手"><a href="#上手" class="headerlink" title="上手"></a>上手</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;新建一个Crawler类，并声明一个<code>PoliteWebCrawler</code>对象。在Abot框架中，<code>PoliteWebCrawler</code>是一切指令和组件的入口。是的，组件，Abot提供了一套高度可自定义的插件接口，它们都可以通过导入<code>PoliteWebCrawler</code>的构造函数来使用。这一点后面会详解。</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> Abot.Crawler;</span><br><span class="line"><span class="keyword">using</span> System;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="title">SampleSearchEngine</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">Crawler</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">readonly</span> PoliteWebCrawler _crawler;</span><br><span class="line">    <span class="keyword">public</span> Uri RootUrl &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125; = <span class="keyword">new</span> Uri(<span class="string">"https://github.com/"</span>);</span><br><span class="line">    <span class="comment">// 储存结果的容器，SitePage包含标题、URL、内容等页面基本元素</span></span><br><span class="line">    <span class="keyword">public</span> Dictionary&lt;<span class="keyword">string</span>, SitePage&gt; Pages &#123; <span class="keyword">get</span>; <span class="keyword">private</span> <span class="keyword">set</span>; &#125; = <span class="keyword">new</span> Dictionary&lt;<span class="keyword">string</span>, SitePage&gt;();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> _totalPages; <span class="comment">// 统计所有找到的页面</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> _pagesCrawled; <span class="comment">// 统计爬过的页面</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Crawler</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>    &#123;</span><br><span class="line">      _crawler = <span class="keyword">new</span> PoliteWebCrawler(); <span class="comment">// 简单构造</span></span><br><span class="line">      <span class="comment">// _crawler = new PoliteWebCrawler(crawlConfig, null, null, null, null, null, null, null, null); // 复杂构造</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  [<span class="meta">Serializable</span>]</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">SitePage</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">string</span> Url &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">string</span> Title &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">string</span> Content &#123; <span class="keyword">get</span>; <span class="keyword">set</span>; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如代码所示，可以看出<code>PoliteWebCrawler</code>有简单和复杂的构造函数。在复杂函数的参数全为<code>null</code>时两者相同，都是使用Abot默认的构建方法。如果有自定义的插件则可以在调用复杂构造函数时引入，但不能在对象已被创建后替换。</p>
<h2 id="自定义爬虫"><a href="#自定义爬虫" class="headerlink" title="自定义爬虫"></a>自定义爬虫</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abot的爬虫由9个部件组成：配置、决策、线程管理、资源调度、页面请求、超链接解析、内存管理，还有robot.txt文件的处理机制。我认为Abot提供的几个默认组件已经能满足绝大多数用户的需求。出于不想跑题的理由，这里只详细谈一谈最重要的决策器。</p>
<h3 id="决策器"><a href="#决策器" class="headerlink" title="决策器"></a>决策器</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一定是每个写爬虫的人最关心的内容之一。开发者可以通过这个接口来决定爬哪些网页，抓取哪些内容，放弃哪些嵌套的链接以及何时需要重新抓取页面。</p>
<figure class="highlight csharp"><figcaption><span>自定义决策逻辑</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">CustomDecisionMaker</span> : <span class="title">CrawlDecisionMaker</span>, <span class="title">ICrawlDecisionMaker</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> CrawlDecision <span class="title">ShouldCrawlPage</span>(<span class="params">PageToCrawl pageToCrawl, CrawlContext crawlContext</span>)</span></span><br><span class="line"><span class="function"></span>  &#123;</span><br><span class="line">    <span class="keyword">if</span> (pageToCrawl.Uri.Authority == <span class="string">"google.com"</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CrawlDecision &#123; Allow = <span class="literal">false</span>, Reason = <span class="string">"不爬取没用的"</span> &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CrawlDecision &#123; Allow = <span class="literal">true</span> &#125;; <span class="comment">// 默认爬取所有网页</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> CrawlDecision <span class="title">ShouldCrawlPageLinks</span>(<span class="params">CrawledPage crawledPage, CrawlContext crawlContext</span>)</span></span><br><span class="line"><span class="function"></span>  &#123;</span><br><span class="line">    <span class="keyword">if</span> (!crawlContext.CrawlConfiguration.IsExternalPageLinksCrawlingEnabled &amp;&amp; !crawledPage.IsInternal)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CrawlDecision &#123; Allow = <span class="literal">false</span>, Reason = <span class="string">"不爬取外部链接"</span> &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CrawlDecision &#123; Allow = <span class="literal">true</span> &#125;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> CrawlDecision <span class="title">ShouldDownloadPageContent</span>(<span class="params">CrawledPage crawledPage, CrawlContext crawlContext</span>)</span></span><br><span class="line"><span class="function"></span>  &#123;</span><br><span class="line">    <span class="keyword">if</span> (crawledPage.HttpWebResponse.StatusCode != HttpStatusCode.OK)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CrawlDecision &#123; Allow = <span class="literal">false</span>, Reason = <span class="string">"只爬取返回OK的网页"</span> &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CrawlDecision &#123; Allow = <span class="literal">true</span> &#125;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用默认决策</span></span><br><span class="line">  <span class="comment">//public CrawlDecision ShouldRecrawlPage(CrawledPage crawledPage, CrawlContext crawlContext)</span></span><br><span class="line">  <span class="comment">//&#123;</span></span><br><span class="line">  <span class="comment">//  if (crawledPage.WebException == null)</span></span><br><span class="line">  <span class="comment">//  &#123;</span></span><br><span class="line">  <span class="comment">//    return new CrawlDecision &#123; Allow = false, Reason = "无异常" &#125;;</span></span><br><span class="line">  <span class="comment">//  &#125;</span></span><br><span class="line">  <span class="comment">//  return new CrawlDecision &#123; Allow = true &#125;;</span></span><br><span class="line">  <span class="comment">//&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果逻辑不复杂，开发者也可以通过植入的方式替换默认的决策逻辑。</p>
<figure class="highlight csharp"><figcaption><span>植入式修改决策逻辑</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">crawler.ShouldCrawlPage((pageToCrawl, crawlContext) =&gt; </span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span> (pageToCrawl.Uri.Authority == <span class="string">"google.com"</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> CrawlDecision &#123; Allow = <span class="literal">false</span>, Reason = <span class="string">"不爬取没用的"</span> &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CrawlDecision &#123; Allow = <span class="literal">true</span> &#125;; <span class="comment">// 默认爬取所有网页</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h3 id="其他的组件"><a href="#其他的组件" class="headerlink" title="其他的组件"></a>其他的组件</h3><ul>
<li>线程管理器：负责多线程的逻辑，我认为使用配置参数来调整其行为足以满足大部分的需求了。</li>
<li>资源管理器：负责调度已被爬取和将要被爬取的页面的仓库。除非使用分布式的架构否则也不需要调整。</li>
<li>页面请求器：负责发送HTTP请求并下载其内容。如果有比较复杂的重定向或用户认证机制便需要重新编写这一类，但如果是常规逻辑则只需要调整配置参数（如使用明文登陆或系统证书等）。</li>
<li>超链接解析器：负责获取页面上的所有超链接并进行筛选。和决策器所不同的是，决策器掌管整个页面的决定，而解析器负责页面内的细节。</li>
<li>内存管理单元：负责统筹进程的内存占用，并在空间不够的情况下做出相应的对策。可以配合配置文件里的最大线程参数一起使用。</li>
<li>最后，robot.txt处理器决定是否听从文件的指示，听从哪些等。一般用户使用默认的就可以。</li>
</ul>
<h2 id="注册监听器"><a href="#注册监听器" class="headerlink" title="注册监听器"></a>注册监听器</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>PoliteWebCrawler</code>会监听5种不同的事件，每种监听又有同步和异步两种模式。如何处理这些事件是业务逻辑中最关键的地方。因此，关于爬虫的绝大部分逻辑都会嵌套进这些监听器中。</p>
<figure class="highlight csharp"><figcaption><span>监听异步事件</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_crawler.PageCrawlStartingAsync += Crawler_ProcessPageCrawlStarting;</span><br><span class="line">_crawler.PageCrawlCompletedAsync += Crawler_ProcessPageCrawlCompleted;</span><br><span class="line">_crawler.PageCrawlDisallowedAsync += Crawler_PageCrawlDisallowed;</span><br><span class="line">_crawler.PageLinksCrawlDisallowedAsync += Crawler_PageLinksCrawlDisallowed;</span><br><span class="line">_crawler.RobotsDotTextParseCompletedAsync += Crawler_RobotsDotTextParseCompleted;</span><br></pre></td></tr></table></figure>


<h3 id="处理页面前"><a href="#处理页面前" class="headerlink" title="处理页面前"></a>处理页面前</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一事件触发于从资源仓库提取之后，处理页面之前。一些记录、页面的预处理可以在这一步进行。</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">Crawler_ProcessPageCrawlStarting</span>(<span class="params"><span class="keyword">object</span> sender, PageCrawlStartingArgs e</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  _totalPages++;</span><br><span class="line">  PageToCrawl pageToCrawl = e.PageToCrawl;</span><br><span class="line">  _logger.Info(<span class="string">$"Crawling <span class="subst">&#123;pageToCrawl.Uri.AbsoluteUri&#125;</span> which was found on page <span class="subst">&#123;pageToCrawl.ParentUri.AbsoluteUri&#125;</span>..."</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="处理页面后"><a href="#处理页面后" class="headerlink" title="处理页面后"></a>处理页面后</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一事件触发于处理页面之后，从仓库中提取下一页面之前。爬虫的主要逻辑都应该放在这里。</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">Crawler_ProcessPageCrawlCompleted</span>(<span class="params"><span class="keyword">object</span> sender, PageCrawlCompletedArgs e</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  CrawledPage crawledPage = e.CrawledPage;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (crawledPage.WebException != <span class="literal">null</span> || crawledPage.HttpWebResponse.StatusCode != HttpStatusCode.OK)</span><br><span class="line">  &#123;</span><br><span class="line">    _logger.Warn(crawledPage.WebException,</span><br><span class="line">    <span class="string">$"Crawl failed for <span class="subst">&#123;crawledPage.Uri.AbsoluteUri&#125;</span>, the host returned <span class="subst">&#123;crawledPage.HttpWebResponse.StatusCode&#125;</span> status code."</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    _logger.Info(<span class="string">$"Crawl of page succeeded <span class="subst">&#123;crawledPage.Uri.AbsoluteUri&#125;</span>"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">string</span>.IsNullOrEmpty(crawledPage.Content.Text))</span><br><span class="line">  &#123;</span><br><span class="line">    _logger.Info(<span class="string">$"Page had no content <span class="subst">&#123;crawledPage.Uri.AbsoluteUri&#125;</span>"</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Use AngleSharp HTML parser.</span></span><br><span class="line">  <span class="keyword">var</span> document = crawledPage.AngleSharpHtmlDocument;</span><br><span class="line">  <span class="keyword">if</span> (!Pages.ContainsKey(crawledPage.Uri.AbsoluteUri))</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// Store page information</span></span><br><span class="line">    Pages.Add(crawledPage.Uri.AbsoluteUri, <span class="keyword">new</span> SitePage</span><br><span class="line">    &#123;</span><br><span class="line">      Url = crawledPage.Uri.AbsoluteUri,</span><br><span class="line">      Title = document.Title,</span><br><span class="line">      Content = document.TextContent, <span class="comment">// 进行一些自定义的页面处理</span></span><br><span class="line">    &#125;);</span><br><span class="line">    _pagesCrawled++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="禁止爬取页面"><a href="#禁止爬取页面" class="headerlink" title="禁止爬取页面"></a>禁止爬取页面</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一事件触发于被禁止获取页面内容后，可以配合robot.txt处理机制和决定器一起使用。</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">Crawler_PageCrawlDisallowed</span>(<span class="params"><span class="keyword">object</span> sender, PageCrawlDisallowedArgs e</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  PageToCrawl pageToCrawl = e.PageToCrawl;</span><br><span class="line">  _logger.Info(<span class="string">$"Did not crawl page <span class="subst">&#123;pageToCrawl.Uri.AbsoluteUri&#125;</span> due to <span class="subst">&#123;e.DisallowedReason&#125;</span>."</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="禁止爬取页面内超链接"><a href="#禁止爬取页面内超链接" class="headerlink" title="禁止爬取页面内超链接"></a>禁止爬取页面内超链接</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一事件触发于被禁止获取页面内某一超链接后，同样需要配合robot.txt处理机制和决定器一起使用。</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">Crawler_PageLinksCrawlDisallowed</span>(<span class="params"><span class="keyword">object</span> sender, PageLinksCrawlDisallowedArgs e</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  CrawledPage crawledPage = e.CrawledPage;</span><br><span class="line">  _logger.Info(<span class="string">$"Did not crawl the links on page <span class="subst">&#123;crawledPage.Uri.AbsoluteUri&#125;</span> due to <span class="subst">&#123;e.DisallowedReason&#125;</span>"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="提取DOM内所有的文字信息"><a href="#提取DOM内所有的文字信息" class="headerlink" title="提取DOM内所有的文字信息"></a>提取DOM内所有的文字信息</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于我的最终目的是要做一个全文字搜索引擎，我需要提取出HTML页面中所有的文字信息。然而我用到的<code>AngleSharp</code>HTML解析器不但会提取出有用的文字信息，还会提取出<code>&lt;script&gt;</code>、<code>&lt;style&gt;</code>标签中的JavaScript和CSS代码…这设计的也太蠢了。于是我只好自己写一个。逻辑不难懂，就是个回溯法。但在彻底理解DOM的定义前走了不少弯路。</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">readonly</span> IEnumerable&lt;<span class="keyword">string</span>&gt; filteredTags = <span class="keyword">new</span> <span class="keyword">string</span>[]</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"STYLE"</span>, <span class="string">"SCRIPT"</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">readonly</span> IEnumerable&lt;<span class="keyword">string</span>&gt; filteredClassNames = <span class="keyword">new</span> <span class="keyword">string</span>[]</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aspnethidden"</span>, <span class="string">"header"</span>, <span class="string">"footer"</span>, <span class="string">"modal"</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">string</span> <span class="title">TraverseDomGetContent</span>(<span class="params">IElement node</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="comment">// Filter unwanted tags and class names (e.g. footers)</span></span><br><span class="line">  <span class="keyword">if</span> (filteredTags.Contains(node.TagName)) <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (node.ClassName != <span class="literal">null</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">string</span> lowerClassName = node.ClassName.ToLower();</span><br><span class="line">    <span class="keyword">if</span> (filteredClassNames.Any(n =&gt; lowerClassName.Contains(n))) <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Get and join all text content from children</span></span><br><span class="line">  <span class="keyword">string</span> childrenJoin = <span class="keyword">string</span>.Empty;</span><br><span class="line">  <span class="keyword">foreach</span> (IElement child <span class="keyword">in</span> node.Children)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">string</span> childString = TraverseDomGetContent(child);</span><br><span class="line">    <span class="keyword">if</span> (childString != <span class="literal">null</span>) childrenJoin += childString + <span class="string">" "</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If all children have no content, return text content of current node.</span></span><br><span class="line">  <span class="comment">// Else return the content of children.</span></span><br><span class="line">  <span class="keyword">string</span> content = childrenJoin == <span class="keyword">string</span>.Empty ? node.TextContent.Trim(trimmedCharacters) : childrenJoin.Trim();</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">string</span>.IsNullOrEmpty(content) ? <span class="literal">null</span> : content;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一切准备完毕后，运行爬虫并验证结果。最后将结果导出至文件或数据库。</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Run</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  CrawlResult result = _crawler.Crawl(RootUrl); <span class="comment">// 注意此为同步任务，且必须同步</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (result.ErrorOccurred)</span><br><span class="line">  &#123;</span><br><span class="line">    _logger.Error(<span class="string">$"Crawl of <span class="subst">&#123;result.RootUri.AbsoluteUri&#125;</span> completed with error: <span class="subst">&#123;result.ErrorException.Message&#125;</span>"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    _logger.Info(<span class="string">$"Crawl of <span class="subst">&#123;result.RootUri.AbsoluteUri&#125;</span> completed."</span>);</span><br><span class="line">    _logger.Info(<span class="string">$"Total pages founded: <span class="subst">&#123;_totalPages&#125;</span>. Pages crawled:<span class="subst">&#123;_pagesCrawled&#125;</span>."</span>);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> DEBUG</span></span><br><span class="line">    ExportToJson(Pages);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    ExportToDatabase(Pages);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ExportToJson</span>(<span class="params">Dictionary&lt;<span class="keyword">string</span>, SitePage&gt; pages</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">string</span> fileName = <span class="string">"output.json"</span>;</span><br><span class="line">  <span class="keyword">string</span> content = JsonConvert.SerializeObject(Pages);</span><br><span class="line">  File.WriteAllText(fileName, content);</span><br><span class="line">  _logger.Info(<span class="string">$"Wrote to <span class="subst">&#123;Path.GetFullPath(Directory.GetCurrentDirectory() + <span class="string">'\\'</span> + fileName)&#125;</span>"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ExportToDatabase</span>(<span class="params">Dictionary&lt;<span class="keyword">string</span>, SitePage&gt; pages</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    _entities.SitePages.AddOrUpdate(pages.Values.ToArray());</span><br><span class="line">    _entities.SaveChanges();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">catch</span> (DbEntityValidationException ex)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">foreach</span> (<span class="keyword">var</span> err <span class="keyword">in</span> ex.EntityValidationErrors)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">foreach</span> (<span class="keyword">var</span> subErr <span class="keyword">in</span> err.ValidationErrors)</span><br><span class="line">      &#123;</span><br><span class="line">        _logger.Error(<span class="string">$"Validation failed for property <span class="subst">&#123;subErr.PropertyName&#125;</span> because <span class="subst">&#123;subErr.ErrorMessage&#125;</span>."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  _logger.Info(<span class="string">"Wrote to database."</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;至此关于Abot爬虫的概览便总结完毕。下一步我想做的是基于SQL Server的简易全文字搜索引擎。具体怎么实现等下回再说。</p>

    
  </div>

</article>


   

   
  <div class="box-prev-next clearfix">
    <a class="show pull-left" href="/2019/04/15/20190414/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="show pull-right" href="/2021/01/15/20200115/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>




</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">关闭</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/archives/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              rel="noopener noreferrer"
              target="_self"
              >
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/link/"
              rel="noopener noreferrer"
              target="_self"
              >
              友链
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/search/"
              rel="noopener noreferrer"
              target="_self"
              >
              搜索
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    

    

    
    

    

    
    

    

  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

</body>
</html>
